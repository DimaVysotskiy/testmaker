# AI Educational Tools Backend

Проект представляет собой backend-сервис на FastAPI для обработки учебных материалов с использованием больших языковых моделей (LLM) через Ollama. Сервис предоставляет инструменты для конвертации лекций в Markdown и создания тестов по содержанию лекций.

## Возможности

- Конвертация лекций из PDF и DOCX в формат Markdown с сохранением структуры и содержания
- Генерация тестов по лекциям с различными типами вопросов и уровнями сложности
- Поддержка Ollama для работы с языковыми моделями

## Использование Ollama Cloud моделей

Проект настроен для работы с облачными моделями Ollama через API. Для использования облачных моделей:

1. Зарегистрируйтесь на [ollama.com](https://ollama.com) и получите API ключ
2. Укажите ваш API ключ в переменной окружения `OLLAMA_API_KEY`
3. Укажите желаемую модель в переменной окружения `LLM_MODEL` (например, `llama3.2`, `mistral`, `gemma` и т.д.)

При использовании облачных моделей через API, сервис будет отправлять запросы напрямую на серверы Ollama, что позволяет использовать мощные модели без необходимости локальной установки.

## Установка и запуск

### Через Docker (рекомендуется)

1. Скопируйте файл `.env.example` в `.env`:
   ```bash
   cp .env.example .env
   ```

2. Отредактируйте файл `.env`, указав ваш API ключ и выбранную модель:
   ```bash
   OLLAMA_API_KEY=ваш_ключ_здесь
   LLM_MODEL=llama3.2
   ```

3. Запустите сервис с помощью docker-compose:
   ```bash
   docker-compose up --build
   ```

### Локальный запуск

1. Установите зависимости:
   ```bash
   pip install -r requirements.txt
   ```

2. Настройте переменные окружения (см. выше)

3. Запустите сервер:
   ```bash
   uvicorn main:app --host 0.0.0.0 --port 8000
   ```

## API Endpoints

- `GET /ping` - Проверка работоспособности сервиса
- `GET /ai-tools/tools-info` - Получение информации о доступных инструментах
- `POST /ai-tools/how_llm_see_my_lecture` - Конвертация лекции в Markdown
- `POST /ai-tools/make_test` - Создание теста по лекции

## Переменные окружения

- `OLLAMA_API_KEY` - API ключ для доступа к сервису Ollama
- `LLM_MODEL` - Название модели Ollama, которую следует использовать

## Требования

- Python 3.9+
- Docker (для запуска в контейнере)

## Структура проекта

```
new_moodle/
├── main.py                # Точка входа приложения
├── docker-compose.yml     # Конфигурация Docker
├── .env.example           # Пример файла переменных окружения
├── routers/              # Маршруты приложения
│   └── ai_tools_router.py
├── utils/                # Утилиты
│   ├── converter.py       # Конвертация файлов в Markdown
│   └── testmaker.py       # Генерация тестов
```